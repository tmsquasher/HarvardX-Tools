Development log

9/22
Fixed the problem with separateClassFiles.py; the cause was a break statement where
there needed to be a continue; the question now is why it worked for some rather than
why it didn't work for all. But since it is working there is little need to track that
down. 

The next step in dealing with the class data will be to determine which of the data
files are empty and not copy those to the class directory, but simply remove them. This 
has been added.

The next step will be to make sure that the log data follows the new naming conventions
that are embodied in this work, and then to change the log processing scripts to deal
with the new naming conventions.  

9/21
Coming up with a class list requires parsing the names of the files. The naming
pattern includes a (useless) prefix of "HarvardX-", followed by a description and
some timing information, followed by a description of the data in the file, ending
with "edx-analytics" and a file extension. The exception to this is the .mongo files;
these have the 'HarvardX-' prefix, a '.mongo' extension, and nothing but the class
name (if an on-line course) or a postfix prior to the extension of '-edge'. 

Current theory: to build a class list that can be used to segregate the data files
by class, use the .mongo files, strip them of the 'HarvardX-' prefix and the 
'.mongo' postfix, and work with the convention that non-edge courses have no 
additional name but that edge courses are marked as '-edge' at the end.

buildClassList.py
	Run either by itself or with a directory as a command-line argument, the
	program will read the names of the file in the directory indicated or the
	current working directory, extracting the names of classes in the files.
	The assumption is that the program will run in a directory that contains
	the class dump from edX. The results will be written, on class-per-line,
	in a file named WeeklyClassList in the working directory.
	
	The module also contains functions that will write the class list from the
	file and read the class list from a file.
	
Question: We have been using the class name to determine what log entries are
associated with the class, since the class name is part of the URL that is in the
log for each event. Is this still true, and is it the name that we are extracting?

Now that we have a list of files, we can create a directory for each file, and 
move all the files associated with a particular class to that directory. Creating
the directories is easy; deciding which directory to move a file to is a bit more
complex since the kind of contents of the file (authorized-user, userprofile, 
and the like) are embedded between the course name and the distinction between
and edX and edge in the name. 

This lead to the current separateClassFiles.py, which attempts to:
	Read the WeeklyClassList file (generated by buildClassList.py);
	Create a directory for each class;
	Finding all of the files that aren't directories that have the
	class name as part of their name;
	Determine, based on what the description of the file is embedded in
	the name, to give it a more descriptive and shorter name, and
	Move the file to the appropriate directory with the shorter (and more
	regular) name.
A current version of this script is working for some files, but not others; it isn't
clear what the differences are; this is where to start next.

9/20
Problem: The whole of the HarvardX research work has been based on an organization
of the files sent by edX into category by class, with the data from each week
living under the class-named directory and aggregation at the class level. The
conventional naming of edX for the classes has been followed.

In the 2013-09-08 data dump edX changed their convention for naming the files 
containing the data, and began to include all data for Harvard courses, including
those for experimental and on-campus courses (the edge courses) and new courses
for the semester. The file count has gone up from 397 in the 2013-09-08 dump
to 925 in the 2013-09-15 dump. In addition, the 2013-09-08 dump contained two 
files for each database extraction; one in .xml format and one in .sql format. The
2013-09-15 dump only contains the .sql format, which means that 184 files in the
earlier dump are not in the later dump.

We need a better way to process the files in the new, expanded dump. We will be
adopting the following strategy:

1) remove any files that are not in use. This includes all of the various wiki
files, which do not contain any data. This will remove 180 files. Remove all 
*Demo* files, which removes an additional 18.Remove all *00-Test* files, which
removes an additional 12. It is unclear if we can remove the *Beta-Test* files;
these have some content but appear to not have much student content. This gets
the listing down to 708 files.

2) Determine the class names from the file names. All of the files begin with 
a preface of "HarvardX-" and end with either "-edx.mongo", "-edx-analytics.sql",
"-edge.mongo", "-edge-analytics.sql". The first two indicate the data is for
an on-line course; the second two indicate that this is an edge course. There is
an on-line course and an edge course for each for each of the classes, but many 
of these are empty or nearly empty. 
	
7/28
course_enrollment.py, user.py, userprofile.py, certificates.py
	All modules that deal with basic file types now have a builddict function (taking
	the data file as supplied by edX and building a dictionary of those fields that
	are still of interest), a readdict (takes a csv file and reconstructs such a
	dictionary) and a writedict (takes a csv file and a dictionary, and writes the
	contents of the dictionary to the file).


3/17
user.py
	Removed the unused fields from the user object. It might makes sense to compress
	the csv files in a separate function that would read in the csv that was created
	by toCSV to remove these fields. This would require a change in the builddict 
	function, but would both save space and probably make everything faster.
	
course_enrollment.py
	Created a module containing an object that encapsulates the course enrollment data.
	This is a simple data file, containing the user id, the course id, and the date of
	enrollment. There is a function to scrub the csv file, and one to build a dictionary
	from the csv file. The internal id is not stored in the object.
	
convertfiles
	Added a package convertfiles, which contains the programs used to convert from xml to 
	csv. Placed toCSV.py, toCSVsmall.py, and xmltocsv.py into this package. Note that
	eclipse got funky at understanding that these modules now live within the package.
	
activity_log
	Added a package activity_log, containing the programs used to extract and manipulate
	the log files that contain all of the course activity. Placed combineLogbyTime.py,
	findEventTypes.py, and splitFiles.py into this package.
	
demographics
	Added a package demographics, containing the programs used to determine the demographics
	for a course. Moved getenrollmentdata,py, ph207demographcis.py, scrubstudentprofile.py, userprofile.py 
	to this package. 
	
demographics/ph207demographics
	Changed the name of the program to demographics.py, and added a first parameter that will
	indicate the name of the course for which the report (and the corresponding file) are
	prepared.

3/16
certificates.py
	Completed first implementation and documentation of the certificate file
	
userprofile.py
	Removed the lang and loc fields from the profile object. These have not been
	used or gathered since the prototype of 6.002x. 
	Added considerable pydoc to the defined functions.
	Moved to using logging rather than print() for error messages	

